{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fast_text_amazon_3_labels.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "yXCk_7VHtiZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package Loading"
      ],
      "metadata": {
        "id": "OO6_d3Ultq4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "!pip install fasttext\n",
        "import fasttext\n",
        "import bz2\n",
        "import csv\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yoxwdo6UtmQs",
        "outputId": "68321980-94ed-4b4f-e332-d58217cb48cb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.6)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.9.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up paths"
      ],
      "metadata": {
        "id": "SxAWWWFXuEvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parent paths\n",
        "google_path = '/content/drive/My Drive/'\n",
        "parent_path = google_path\n",
        "folder_path = 'Web_Mining_Project/fasttext/3labels'\n",
        "\n",
        "path_shortend_dataset = parent_path + \"Web_Mining_Project/data/shortend10000_dataset.csv\"\n",
        "path_train = parent_path + folder_path + 'train_text.txt'\n",
        "path_test = parent_path + folder_path + 'test_text.txt'\n",
        "path_valid = parent_path + folder_path + 'valid_text.txt'"
      ],
      "metadata": {
        "id": "PAmnBOwxuHmS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up functions"
      ],
      "metadata": {
        "id": "hLuVlcpZz88y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function for sentiment label creating \n",
        "def create_labels_from_rating(score):\n",
        "  score = int(score)\n",
        "  if score <= 2:\n",
        "    return 0 #negative\n",
        "  elif score == 3:\n",
        "    return 1 #neutral\n",
        "  else:\n",
        "    return 2 #positive\n",
        "\n",
        "def convert_labels(label):\n",
        "  label = int(label)\n",
        "  if label == 1:\n",
        "    return '__label__1'\n",
        "  elif label == 2:\n",
        "    return '__label__2'\n",
        "  else:\n",
        "    return '__label__0'"
      ],
      "metadata": {
        "id": "ks4SIl7gz_Ly"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Train Test split and Data Preparation"
      ],
      "metadata": {
        "id": "lRsP-vLlxXcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare data \n",
        "df = pd.read_csv(path_shortend_dataset)\n",
        "df['label'] = df['overall'].apply(create_labels_from_rating)\n",
        "df['text'] = df['reviewText']\n",
        "df.drop(columns=['overall', 'verified', 'reviewTime', 'reviewerID', 'asin', 'reviewerName', 'summary', 'unixReviewTime', 'vote', 'style', 'image'], inplace = True)\n",
        "df['label'] = df['label'].apply(convert_labels)\n",
        "print(df.head())\n",
        "\n",
        "#train, test, valid\n",
        "train, test = train_test_split(df, test_size=0.2, random_state = 453, stratify=df['label'])\n",
        "test, valid = train_test_split(test, test_size=0.5 , random_state = 453, stratify= test['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GBkfqdtxbmp",
        "outputId": "52c1c0e7-05aa-4abc-f59d-19eb0a1f8499"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                         reviewText       label  \\\n",
            "0           0  This game is a bit hard to get the hang of, bu...  __label__2   \n",
            "1           1  I played it a while but it was alright. The st...  __label__2   \n",
            "2           2                                           ok game.  __label__1   \n",
            "3           3  found the game a bit too complicated, not what...  __label__0   \n",
            "4           4  great game, I love it and have played it since...  __label__2   \n",
            "\n",
            "                                                text  \n",
            "0  This game is a bit hard to get the hang of, bu...  \n",
            "1  I played it a while but it was alright. The st...  \n",
            "2                                           ok game.  \n",
            "3  found the game a bit too complicated, not what...  \n",
            "4  great game, I love it and have played it since...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformation to txt"
      ],
      "metadata": {
        "id": "ilXjc79O1lD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create needed txts\n",
        "train.to_csv(path_train, index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n",
        "valid.to_csv(path_valid, index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n",
        "test_labels = []\n",
        "test_text = []\n",
        "for index, row in test.iterrows():\n",
        "    test_text.append(row['text'])\n",
        "    test_labels.append(row['label'])"
      ],
      "metadata": {
        "id": "iJoeqznI1pYp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "Plx6C6wH2Tcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# without hyperparameter optimization\n",
        "#model = fasttext.train_supervised(path_train, label_prefix='__label__', thread=4, epoch = 10)\n",
        "\n",
        "# with hyperparameter optimization\n",
        "model = fasttext.train_supervised(input=path_train, autotuneValidationFile=path_valid, autotuneDuration=600)\n"
      ],
      "metadata": {
        "id": "OBSca5m02VHz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "yYODOnfp9ru2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = [x.replace('\\n', '') for x in test_text]\n",
        "\n",
        "# Use the predict function \n",
        "prediction = model.predict(test_text)\n",
        "\n",
        "# check the first record outputs\n",
        "print(prediction[0][0], 'prediction for first item')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8VMGzYo93jH",
        "outputId": "6a89f605-3a80-4e6b-dc60-2d8631b0b2f8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__label__2'] prediction for first item\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_labels]\n",
        "prediction_labels = [0 if x == ['__label__1'] else 1 for x in prediction[0]]\n",
        "\n",
        "# run the accuracy measure. \n",
        "#print(roc_auc_score(labels, pred_labels))\n",
        "print(f1_score(labels, prediction_labels, average = 'weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muxReMDr-WuI",
        "outputId": "cd7012f4-31d7-4e14-c3f5-dd598870eadd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8945935145392645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ddps0Umz2hrD"
      }
    }
  ]
}